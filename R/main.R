#' Generate simulation data
#'
#' @description The function \code{simulateExample} generates a NPClustData object from a simulates dataset of desired size
#' @import MASS
#' @import mvtnorm
#' @param n Number of subjects
#' @param p Number of variables
#' @param prop.X.miss Proportion of missing data
#' @param tau The variance parameter for regular variables
#' @param tau_0 The variance paramter for high variation vatiables
#' @export
simulateExample <- function(n = 25, p = 250, prop.X.miss=0, tau = 0.5, tau_0 = 1.25) {

	###################
	# generate covariates adding random noise of specified level
	# create objects data and true
	###################

	true_parm <- gen.clust(n, p)

	true_parm$tau <- tau
	true_parm$tau_0 <- tau_0

	sim.X <- gen.X(n, p, prop.X.miss, true_parm)

	simulation <- list(data = sim.X$data, true = sim.X$true, true_parm = true_parm)
	class(simulation) <- "NPClustData"

	return(simulation)
}

#' Create a NPClustData object from a dataset
#'
#' @description The function \code{npclustData} creates a NPClustData object from the dataset to be analyzed.
#'
#' @param raw_data a \eqn{n * p}{n * p} matrix containing observation values from n subjects on p variables
#' @param M The concentration parameter of DP for latent elements
#' @param b0 The concentration parameter of column-intercept cluster
#' @param b1 The concentration parameter of PDP for column clustering
#' @details The function \code{npclustData} integrates data and prefixed model constants to create a NPClustData object to be passed to \code{\link{npclustFit}} for cluster analysis.
#'
#' @export
npclustData<-function(raw_data,M=10,b0=2.2,b1=20) {
  data <- NULL
  data$X<-raw_data
  p<-ncol(raw_data)
  n2<-n<-nrow(raw_data)
  # data$missing.indx <- NULL
  # data$non.missing.indx <- 1:n

  data$K.max <- round(n2/2)
  data$G.max <- round(p/2)

  data$Y <- rep(0,n2)
  data$delta <- rep(0,n2)
  data$true <- NULL
  data$true$Y <- data$Y
  data$true$delta <- data$delta

  true<-NULL
  true$a.R <- M
  true$b0 <- b0
  true$b1 <- b1

  true$shift <- 1e-4

  real_data <- list(data = data, true = true, true_parm = NULL)
  # real_data$data<-data
  # real_data$true<-true
  # real_data$true_parm<-NULL
  class(real_data) <- "NPClustData"

  return(real_data)
}

#' Apply Bayesian nonparametric clustering to a dataset
#'
#' @description \code{npclustFit} performs Bayesian nonparametric clustering introduced in VariScan model.
#' @param npclustDataObj The NPClustData object containing the data to be analyzed. This can be generated by \code{\link{npclustData}} from a real dataset or \code{\link{simulateExample}} for a simulated dataset.
#' @param n.burn Number of burn-in samples to be generated
#' @param n.reps Number of post burn-in samples to be generated
#' @param max.row.nbhd.size Maximum neighborhood size for sampling parameters of DP for latent vector elements, should be small compared to \eqn{n*p^d}{n*p^d}
#' @param max.col.nbhd.size Maximum neighborhood size for sampling parameters of PDP for variable clustering, should be small compared to \eqn{p}{p}
#' @param row.frac.probes The fraction of neighborhood assignment being updated in DP for latent vector elements
#' @param col.frac.probes The fraction of neighborhood assignment being updated in PDP for variable clustering
#' @param prob.compute.col.nbhd The probability of computing the neighborhood assignment in PDP for variable clustering
#' @param dahl.flag Whether or not to compute the least-squares allocation (not included for now)
#' @param standardize.X Whether or not to standardize the variables
#' @param flip.sign ???
#' @param tBB_flag Whether or not to compute the \eqn{X^{T} X}{X^T X} for regression
#' @param taxicab Whether or not to compute the taxicab distance which measures variable clustering accuracy for simulated datasets
#' @param computeMode The computeMode object to be used, generated by \code{\link{createComputeMode}}.
#'
#' @return An object which is a list of MCMC samples for following:
#' \item{rng}{???}
#' \item{K.v}{Number of atoms in the PDP base measure from DP}
#' \item{G.v}{Number of detected clusters among variables}
#' \item{tau_int.v}{The standard deviation parameter associated with intercept cluster}
#' \item{tau.v}{The standard deviation parameter for regular variables}
#' \item{tau_0.v}{The standard deviation parameter for high variation vatiables}
#' \item{d.v}{The PDP discount parameter}
#' \item{PDP_log.BF}{The lower bound log-Bayes factor favoring a PDP model instead of DP}
#' \item{row.flip.v}{The Metropolis-Hastings acceptance rate for sampling DP parameters for latent vector elements}
#' \item{col_flip.v}{The Metropolis-Hastings acceptance rate for sampling PDP parameters for variable clustering}
#' \item{col_exit.v}{The proportion for the fast PDP sampling algorithm to propose the exact same allocations as the previous MCMC sample for variables in a nighborhood}
#' \item{col_new_clust.v}{Proportion of opening a new PDP cluster among all variables}
#' \item{nbhd_max}{The maximum distance among the neighborhoods in the fast PDP sampling algorithm}
#' \item{pi.mt}{???}
#' \item{pi.mt2}{???}
#' \item{parm}{All parameter values for the last MCMC sample}
#' \item{init.parm}{All parameter values obtained from initialization}
#' @examples
#' \dontrun{
#'
#' ## Simulations
#'
#' # Simulate data
#' simulation <- simulateExample(n = 25, p = 125)
#'
#' # Apply the Bayesian nonparametric clustering
#' posterior <- npclustFit(simulation, n.burn = 10, n.reps = 20, taxicab = T)
#'
#' # Summarize posterior
#' d_credible.v <- quantile(posterior$d.v, prob=c(.025,.975)) # The posterior credible interval for PDP discount parameter
#' mean.taxicab <- mean(posterior$mean.taxicab.v) # The mean taxicab distance
#' se_mean.taxicab <- sd(posterior$mean.taxicab.v)/sqrt(length(posterior$mean.taxicab.v)) # The standard error of mean taxicab distance
#'
#' ## Real datasets (DLBCL)
#'
#' # Take a subset of the dataset
#' raw_data<-as.matrix(dlbcl[sample(1:nrow(dlbcl),size=100),sample(1:ncol(dlbcl),size=500)])
#'
#' # Convert data to NPClustData object
#' real_data<-npclustData(raw_data)
#'
#' # Apply the Bayesian nonparametric clustering
#' posterior <- npclustFit(real_data, n.burn = 10, n.reps = 20, computeMode = createComputeMode(language = "C"))
#'
#' # Analyze results
#' quantile(posterior$d.v, prob=c(.025,.975)) # The posterior credible interval for PDP discount parameter
#' hist(posterior$G.v) # Histogram of the posterior of number of detected clusters among variables
#' posterior$parm$clust$c.v # The variable cluster allocations from the last MCMC sample
#' posterior$parm$clust$C.m.vec # The variable cluster sizes, aligned in order of cluster number, from the last MCMC sample
#' }
#'
#' @references Guha, S., & Baladandayuthapani, V. (2016). A nonparametric bayesian technique for high-dimensional regression. \emph{Electronic Journal of Statistics}, 10(2), 3374-3424. DOI: 10.1214/16-EJS1184
#'
#' @useDynLib NPCluster, .registration = TRUE
#' @importFrom Rcpp evalCpp
#' @importFrom RcppParallel RcppParallelLibs
#'
#' @export
npclustFit <- function(npclustDataObj,
											 n.burn = 10,
											 n.reps = 20,
											 max.row.nbhd.size = round(.1*25*125^.5), # should be small compared to n2*p^d (~ n2*G if d=.5)
											 max.col.nbhd.size = round(.05*125), # should be small compared to p
											 row.frac.probes = 0.05,
											 col.frac.probes = .1,
                       prob.compute.col.nbhd=.2,
											 dahl.flag=FALSE,
											 standardize.X=FALSE,
											 flip.sign=FALSE,
											 tBB_flag=FALSE,
											 taxicab=FALSE,
											 computeMode = createComputeMode()) {

	if (!inherits(npclustDataObj, "NPClustData")) {
		stop("Wrong data structure")
	}

  if (!inherits(computeMode, "computeMode")) {
    stop("Wrong compute mode")
  }

  if (!standardize.X & flip.sign) {
    stop("Invalid input parameters-- flip.sign cannot be TRUE when standardize.X is FALSE")
  }


	###################
	# Detect clusters
	###################

	posterior <- fn.mcmc(text="CLUST ANALYZE...",
											 npclustDataObj$true, npclustDataObj$data,
											 n.burn, n.reps, max.row.nbhd.size, max.col.nbhd.size, row.frac.probes, col.frac.probes,
											 prob.compute.col.nbhd, npclustDataObj$true_parm, dahl.flag=dahl.flag, standardize.X, flip.sign, tBB_flag, taxicab=taxicab, computeMode)
	return (posterior)
}

#' Profile a simulated example
#' @export
profileExample <- function(n = 25,
													 p = 250,
													 n.burn = 10,
													 n.reps = 20,
													 row.frac.probes = 0.05,
													 col.frac.probes = 0.05,
													 computeMode = createComputeMode(),
													 filename = "Rprof.out") {
	simulation <- simulateExample(n, p)

	Rprof(filename = filename, line.profiling = TRUE, interval = 0.001)
	posterior <- npclustFit(simulation, n.burn = n.burn, n.reps = n.reps,
	           row.frac.probes = row.frac.probes,
	           col.frac.probes = col.frac.probes, taxicab = T,
	           computeMode = computeMode)
	Rprof(NULL)
	#summaryRprof(lines = "show")$by.self

	.printEngineTiming(computeMode$device$engine)
	return(posterior)
}


#' Define Compute Mode
#'
#' The function \code{createComputeMode} creates a computeMode object controling the computation mode to be used including R and C++
#' @export
createComputeMode <- function(language = "R",
                              exactBitStream = FALSE,
                              extraSort = TRUE,
                              completeTest = FALSE,
                              tolerance = 1E-10,
                              specialMode = NULL,
                              test1 = FALSE,
                              test2 = FALSE,
                              test3 = FALSE,
                              lowLevelTiming = FALSE) {
  if (!(language %in% c("C","R"))) {
    stop("Invalid language")
  }

  useR <- (language == "R")
  device <- NULL
  if (!useR) {
    cMode <- 0
    if (!is.null(specialMode)) {
      if ("tbb" %in% tolower(specialMode)) {
        cMode <- cMode + 2
      }
      if ("sse" %in% tolower(specialMode)) {
        cMode <- cMode + 4
      }
    }
    if (lowLevelTiming) {
      cMode <- cMode + 1
    }
    doSort <- (exactBitStream | extraSort)
    device <- .createEngine(doSort, cMode)
  }

  object <- list(
    computeR = (language == "R" | completeTest),
    computeC = (language == "C"),
    device = device,
    exactBitStream = exactBitStream,
    extraSort = extraSort,
    tolerance = tolerance,
    test1 = test1,
    test2 = test2,
    test3 = test3,
    useCPdp = !exactBitStream,
    useCPmf = TRUE,
    useCLogLike = !exactBitStream,
    useCTab = TRUE,
    useCRho = !exactBitStream,
    useCAccept = !exactBitStream,
    useCPdpLike1 = TRUE,
    useCPdpLike2 = TRUE,
    useCGibbs = TRUE,
    useCMarg = TRUE
  )
  class(object) <- "computeMode"
  return(object)
}

#' assertEqual
assertEqual <- function(x, y, tolerance = 0) {
  if (length(x) != length(y)) {
    cat("C++ error -- length:", length(x), length(y))
    recover()
  }
  if (any(abs(x - y) > tolerance)) {
    cat("C++ error -- value:", x, y, abs(x - y), tolerance, sep = "\n")
    recover()
  }
}


